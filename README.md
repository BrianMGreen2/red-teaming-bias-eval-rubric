# red-teaming-bias-eval-rubric
A structured red-teaming framework for evaluating generative AI outputs across multiple bias dimensionsâ€”including framing, omission, tonality, and group identity distortion. Designed to support adversarial testing, responsible model tuning, and policy-aligned mitigation strategies in high-stakes AI applications
